{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VAE\n",
    "- a Probabilistic take on the Autoencoder\n",
    "- AE is a model which takes high dimensional input data and compresses it into a smaller representation\n",
    "\n",
    "\n",
    "- __a VAE maps the input data into the parameters of a probability dist., such as the mean and variance of a Gaussian__\n",
    "- Produces a continous, structured latent space, which is useful for image generation\n",
    "\n",
    "<img src='img/0505_1.png' width='400'>  \n",
    "\n",
    "<center> \n",
    "    Hands-On Machine Learning, 2nd edition\n",
    "</center>\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -q tensorflow-probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 20.3.3; however, version 21.1.1 is available.\n",
      "You should consider upgrading via the 'c:\\users\\hj\\anaconda3\\envs\\test_ten\\python.exe -m pip install --upgrade pip' command.\n",
      "WARNING: You are using pip version 20.3.3; however, version 21.1.1 is available.\n",
      "You should consider upgrading via the 'c:\\users\\hj\\anaconda3\\envs\\test_ten\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "# to generate gifs\n",
    "!pip install -q imageio\n",
    "!pip install -q git+https://github.com/tensorflow/docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Ipython import display\n",
    "\n",
    "import glob\n",
    "import imageio\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Load the MNIST dataset\n",
    "- A vector of 784 integers (28*28)\n",
    "- 0-255\n",
    "\n",
    "\n",
    "- Model each pixel with a Bernoulli dist and statically binarize the data (정적으로 이진화한다)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_images, _), (test_images, _) = tf.keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(images):\n",
    "    images = images.reshape((image.shape[0], 28, 28, 1)) / 255.\n",
    "    return np.where(images > .5, 1.0, 0.0).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = preprocess_image(train_images)\n",
    "test_images = preprocess_image(test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = 60000\n",
    "batch_size = 32\n",
    "test_size = 10000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Batch and shuffle the data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = (tf.data.Dataset.from_tensor_slices(train_images)\\\n",
    "                 .shuffle(train_size).batch(batch_size))\n",
    "test_data = (tf.data.Dataset.from_tensor_slices(test_images)\n",
    "            .shuffle(test_size).batch(batch_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    - from_tensor_slices : numpy array나 list를 tensor dataset으로 변환"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Define the encoder and decoder networks\n",
    "- Use two small ConvNets for the Encoder and Decoder networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### Encoder network\n",
    "> - defines __the approximate posterior distribution $q(z|x)$__, when $z$ is latent variable\n",
    "> \n",
    "> \n",
    "> - In this example, simply model the dist. as a diagonal Gaussian\n",
    "> - outputs the mena and log-variance parameters of a factorized Gaussian (use log-variance for numerical stability)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### Decoder network\n",
    "> - defines __the conditional distribution of the observation $p(x|z)$__\n",
    "> - Model the latent dist.prior $p(z)$ as a unit Gaussian"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### Reparameterization trick\n",
    "> <img src='img/0505_2.png' width='600'>\n",
    "> \n",
    "> <br>\n",
    "> \n",
    "> \n",
    "> - To generate a sample $z$, you can sample from the latent distribution\n",
    "> - But, by this sampling operation, backpropagation cannot flow through a random node  \n",
    "> => __Reparameterization trick!__\n",
    "> <img src='img/0505_4.png' width='300'>  \n",
    "> \n",
    "> \n",
    "> - $\\epsilon$ is a random noise, while $\\mu$ and $\\sigma$ is a fixed value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
